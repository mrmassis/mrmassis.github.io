---
title: "Observabilidade"
date: 2020-11-07T20:05:10-03:00
author: "MRMassiS"
authoravatar: "https://cdn4.iconfinder.com/data/icons/gray-user-management/512/rounded-512.png"
authorbio: "PhD in Cloud Computing, DevOps at SERPRO, and Open Source Enthusiast."
authorlocation: "Curitiba, Brasil"
draft: false
comments: true
share: true
---

Nesta postagem vou relatar alguns pontos referentes as minhas aventuras em observabilidade de ambientes e sistemas ;) assim como sintetizar muito das experiencias e relatos de outros desenvolvedores e DevOps. O termo observabilidade (de *observability*) é muito abrangente e muitas vezes referenciado de maneiras distintas. Estas distinções podem levar a confusão por parte dos interessados neste tema tão abrangente. Eu costumo interpretar essas referências não como divergências, mas sim como pontos de vistas distintos acerca do mesmo tema. Contudo, para não ficar muito desconexo e ter um lastro em comum, costumo utilizar como ponto de partida a definição formal de observabilidade oriunda da [teoria de controle]() onde:

> (...) é uma medida que descreve o quão bem podem ser inferidos os estados de um sistema a partir do conhecimento de suas saídas externas. 

Mas o que é possível entender desta definição? Na minha interpretação tal definição relata que a observabilidade é um conjunto de técnicas, ferramentas e abordagens que possibilitam inferir o estado de um sistema a partir de suas saídas externas. As saídas externas podem ser indicadores de funcionamento do sistema (consumo de memória, uso de CPUs, etc), eventos de utilização e comportamento (ex. registros de logs), correlação entre componentes do sistemas (trace por exemplo) e por ai vai. A organização e a categorização de cada uma dessas saídas externas podem ser agrupadas em determinados subconjunto. Sendo estes subconjuntos referenciados em várias documentações como pilares da observabilidades. Assim temos três os pilares: 

![Pilares](/images/pillars.png)

Mesmo alguns autores divergindo na quantidade de pilares da observabilidade e outros autores como ([Ben Sigelman](https://dzone.com/users/2809513/bensigelman.html)) que acreditam que não há pilares ou eles estão desmoronando, meu entendimento sobre observabilidade segue as opniões de [Tyler Treat](https://medium.com/@tyler_treat), [Cindy Sridharan](https://copyconstruct.medium.com/) e de vários outros autores que consideram os três pilares apresentados na figura acima e os interpretam como *facilitadores para tornar ambientes mais observáveis*.

Descrevendo tais pilares temos:

* *Logs*: são registros de atividades que acontecem dentro do sistema de interesse. São os dados que utilizamos quando uma anomalia acontece no ambiente de interesse. Os registros de logs são dependentes dos sistemas de interesse, sendo papel dos responsáveis por eles na camada de OPS realizar a normalização e estrutura de tais registros.
 
* *Métricas*: de acordo com Erin Baez uma métrica é um valor numérico mensurável em um período de tempo. As métricas são dados utilizado em ambientes de monitoramento para determinar a saúde de um sistema. Métricas podem ser atreladas a alarmes que soam quando determinadas circunstâncias ocorrem (uma métrica exceder um *threashold* por exemplo). Um consideração que deve ser realizada é que a efetividade de uma métrica é quase nula sem um contexto ou parâmetros de referencia. Como podemos saber se o consumo de memória de uma aplicação está alto senão sabemos quanto o sistema como todo tem disponível, assim como o comportamento médio da própria aplicação.

* *Traces*: podem ser considerados trilhas de registros de acontecimentos durante a execução de sistemas. Consistem de uma série de metadados (nome, timestamp, ID, etc.), interconexões (dizendo os processos que invocaram a ação registrada), e as ações. Traces possibilitam seguir por trilhas que tem origem no problema de interesse, até todos os elementos que precederam tal acontecimento. É um insumo útil para determinar possíveis causas de lentidão de um ambiente, da quebra da execução de um sistema, etc.

> **NOTA**: alguns autores, assim como eu, determinam *eventos* como registros de logs acrescidos de metadados como, por exemplo, contexto e/ou rótulos.

Juntos os três pilares podem oferecer todos os insumos para que os estados de um sistema, e quando falo em sistema estou considerando aplicações e serviços em geral, possam ser identificados e os possíveis comportamentos futuros possam ser inferidos. Quanto mais dados obtemos do sistema, mais informações temos sobre ele e consequentemente melhor precisão temos sobre a inferência do seu comportamento, com isso é possível mantermos a avaliabilidade e saúde do sistema.

Observabilidade se tornou o assunto do momento, e muito se fala sobre ele em *blogs*, *fóruns* e *sites* pela Internet. No conjunto de postagens sobre observabilidade (parte [1](https://blog.realkinetic.com/microservice-observability-part-1-disambiguating-observability-and-monitoring-656b4c483495) e [2](https://blog.realkinetic.com/microservice-observability-part-2-evolutionary-patterns-for-solving-observability-problems-a053ae995a21)) [Tyler Treat](https://medium.com/@tyler_treat) expõem seu ponto de vista sobre o tema considerando como pano de fundo as arquiteturas de microsserviços, como o caso do Kubernetes. Considerando a definição de observabilidade utilizada por ele: *habilidade de para perguntar questões sobre um sistema sem conhecer aquelas questões previamente*, Tyler descreve quatro problemas envolvendo este tema: *fadiga de agentes*, *capacidade*, *previsão*, e *ferramentas de acesso aos dados*.

1. *Fadiga de agentes*: este problema é inerente a quantidade de ferramentas voltadas à observabilidade utilizadas nos ambientes alvos. A quantidade de agentes presentes para coleta de logs, métricas, relações de *trace*, etc. contribui negativamente para as atividades de OPS, assim como aumentam o consumo de recursos dentro ambiente (CPU, memória, disco, etc.). Tal quantidade é reflexo da carência de padrões entre os agentes, da falta de estudos em relação ao tipo de soluções serão implantadas e qual o sistema foco destes agentes.

2. *Capacidade*: um plano de capacidade também deve ser considerado quando se trabalha com observabilidade, principalmente quando o foco são ambientes de microsserviços escaláveis como, por exemplo, o Kubernetes. Nesse cenário um aumento no pico de acesso a determinados sistemas pode acarretar na escala horizontal dos respectivos componente. A escala de componentes, por sua vez, aumenta o volume dos dados de observabilidade. Outro problema relacionado a capacidade é em relação a quantidade de licenças de ferramentas proprietárias que podem ser violadas quando trabalhando em ambientes escaláveis. 

3. *Necessidade de previsão*: de acordo com o ponto de vista do Tyler, a observabilidade deve ser capaz de responder perguntas que ainda não conhecemos. Para que isso seja possível, é necessário termos dados. Logo é necessário estimar, ou prever, a geração dos dados mesmo não precisando deles naquela momento. A geração pode ser feita reativamente, quando a pergunta já foi formulada mas ela ainda não pode ser respondida, ou proativamente, o que é mais difícil de acontecer. No primeiro cenário a demanda já ocorreu e haverá um *gap* até que seja possível satisfazê-la. Já no modo proativo, senão for usados alguns modelos estatísticos e matemáticos como aproximações, a geração de dados será um problema impossível de resolver.

4. *Ferramentas de acesso aos dados*: definir o conjunto de ferramentas capazes de acessar e tratar os dados recebidos de várias fontes em um ambiente heterogêneo é um problema correlacionados que também permeia a observabilidade. Como buscar o dados das diversas fontes e entregá-los a diversas ferramentas interessadas é um desafio em aberto que deve ser tratado neste contexto. 

5. *Impactos da precisão*: somado aos quatro desafios propostos por Tyler, também exploro os impactos do nível de precisão, isto é o nível de detalhamento, que estamos interessados em obter sobre os estados de um sistema. Possíveis impactos no sistema e na infraestrutura podem ocorrer quando buscamos mais detalhamento, isto porque o nível de detalhamento esta intimamente ligado ao volume de dados de observabilidade. Este volume tem um custo, e deve ser levado em consideração. A busca por precisão também gera uma carga proporcional à infraestrutura utilizada: *mais dados trafegando* e *mais recursos sendo consumidos*. Isto pode gerar um problema extra pois provoca um *overhead* em todo o ambiente. Por fim, a retenção também é impactada pela precisão, mais dados significa mais armazenamento o que é multiplicado por *N* dias retenção.

6. *Intrusividade*: também acredito que as definições das fronteiras do *mensurável e obteníveis*, ou seja, as fronteiras que delimitam até a onde posso obter dados sem comprometer a privacidade do sistema, deve ser um ponto de atenção em um ambiente de observabilidade. Ultrapassar a fronteira delimitada (seja em contrato ou definida com bases éticas) pode levar a problemas que extrapolam o técnico e entram em outras esferas (jurídica por exemplo).

[Fathima Dihasha](https://medium.com/@dilhasha.nazeer) engenheira sênior de software da WSO2, em sua série de postagens ([1](https://medium.com/the-devops-journey/observability-monitoring-part-01-92efec9f1c0d), [2](https://medium.com/the-devops-journey/observability-monitoring-part-02-d4d81b67c09a), [3](https://medium.com/the-devops-journey/observability-monitoring-part-03-35a4601c0380), e [4](https://medium.com/the-devops-journey/observability-monitoring-part-04-8742a06caff4)) sobre observabilidade, confronta o conceito de observabilidade com as atividades de monitoração chegando a definição que: *observabilidade é uma propriedade de um sistema e monitoramento é um atividade realizada sobre um sistema*. Tal autora foca suas atenções nas métricas e sugere um ciclo de vida de métricas dentro do contexto da observabilidade que também podem ser estendidos para outros pilares. Para ela, o monitoramento deve cobrir cinco estágios:

1. Exposição das métricas de interesse.
2. Coleta das métricas expostas.
3. Armazenamento das métricas coletadas.
4. Visualização das métricas armazenadas.
5. Mecanismos de alerta de anomalias das métricas.

Desconsiderando o primeiro estágio, que para logs é gerados pelo sistema de interesse, todas as quatro demais podem ser consideradas para dados de logs. Sintetizando todas as definições, pontos de vistas e considerações realizadas anteriormente, é possível a descrever uma definição um pouco mais completa sobre a observabilidade.

> A observabilidade é um ambiente composto por um conjunto de ferramentas, as quais são voltadas para um ou mais pilares fundamentais: logs, métricas e trace. Por meio da observabilidade é possível responder perguntas que já foram ou ainda não foram concebidas. Com isso é possível manter a saúde dos sistemas os quais a observabilidade foi aplicada.

### Pipeline da Observabilidade
Assumindo as lições aprendidas por meio dos problemas e das limitações apresentadas anteriormente, e baseado nas ideias e soluções apresentadas nos artigos citados ao longo do texto, descrevo a seguir um conjunto de etapas que vão da coleta a entrega de dados de observabilidade. Essa sequência de passo é consenso a todos os entusiastas do tema, e descreve um *pipeline* com 4 estágios: *1-coleta; 2-envio; 3-roteamento; 4-armazenamento e disponibilização*. Um resultado diretos do  *pipeline* e que cada estágio pode ser tratado como um problema específico e as melhores práticas daquele tipo de problemas pode ser aplicadas sem afetar os demais estágios. 

A próxima figura apresenta graficamente as quatro etapas envolvidas neste *pipeline*, destacando os estágios, os respectivos problemas e os pontos de atença de cada um deles.

![Pipeline da Observabilidade](/images/pipeline.png)

Estágios:

1. *Coleta*: primeiro estágio! É onde é realizada a coleta dos dados de observabilidade (métricas, registros de logs, etc). As ferramentas que contemplam este estágio podem estar no domínio da origem dos dados, assim como podem estar em domínios diferentes. 

2. *Envio*: o envio é o *endpoint* das ferramentas de coleta (estágio 1). Podem ser aplicadas filas ou mecanismos semelhantes para prover, entre outras coisas, prioridades e resiliência (*buffers* em disco de armazenamento, alta-disponibilidade por exemplo).

3. *Roteamento*: o roteamento consiste na retirada dos dados de observabilidade das estruturas providas pelo estágio 2, e encaminhá-las para os destinatários. Por exemplo, um registro de log pode ser enviado para uma ferramente de análise e para um repositório de longa duração para fins de auditoria.

4. *Armazenamento e Distribuição*: os destinatários do estágio 3 (roteamento) se encontram aqui. Podem ser repositório de longa duração, ferramentas de agregação, ferramentas de pesquisa e análise e assim por diante. O estágio 4 é o último estágio do pipeline e ponto final dos dados que foram emitidos pelo sistema antes do estágio 1 (coleta).

### A Seguir!

Nas próximas postagens vou explorar cada um dos três pilares considerados (logs, métricas e trace) destacando algumas das ferramentas *opensources* disponíveis e minhas experiencias em cada um destes subconjuntos. 

- https://www.oreilly.com/library/view/distributed-systems-observability/9781492033431/
- https://blog.realkinetic.com/microservice-observability-part-1-disambiguating-observability-and-monitoring-656b4c483495
- https://blog.realkinetic.com/microservice-observability-part-2-evolutionary-patterns-for-solving-observability-problems-a053ae995a21
- https://medium.com/the-devops-journey/observability-monitoring-part-01-92efec9f1c0d
- https://medium.com/the-devops-journey/observability-monitoring-part-02-d4d81b67c09a
- https://medium.com/the-devops-journey/observability-monitoring-part-03-35a4601c0380
- https://medium.com/the-devops-journey/observability-monitoring-part-04-8742a06caff4

> **NOTA**: é importante ressaltar que o conteúdo apresentado é baseado no meu ponto de vista, e não tem a pretensão de ser uma verdade que se sobressaia sobre outras "verdades". São interpretações que consideraram minhas experiências de uso de vida ao longo dos anos em TIC.
